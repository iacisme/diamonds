{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2493340-0992-4dbc-b00d-0894395111d3",
   "metadata": {},
   "source": [
    "<h1 style='color:rgb(52, 152, 219)'; align=center><font size = 8> DIAMOND PRICES - ANALYSIS AND MODELING </font></h1>\n",
    "\n",
    "<h2 style='color:rgb(52, 152, 219)'; align=left><font size = 6> NOTEBOOK 00-01: OBJECTIVES & METHODOLOGY </font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f681aaf-4992-4617-8cfe-a1c0f601b17f",
   "metadata": {},
   "source": [
    "# REVISION HISTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a51ae1-b030-4561-8ae4-a405ae2b8ec7",
   "metadata": {},
   "source": [
    "| REV | DESCRIPTION             | DATE         |  BY   | CHECK | APPROVE  |\n",
    "|:---:|:-----------------------:|:------------:|:-----:|:-----:|:--------:|\n",
    "| A0  | ISSUED FOR REVIEW (IFR) | 2024-APR-XX  |  IAC  |       |          |\n",
    "|     |                         |              |       |       |          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c1e22-8143-40d1-a7c7-bc300d37a027",
   "metadata": {},
   "source": [
    "## DETAILED DESCRIPTION OF REVISIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4652287-78a7-47f7-a88d-e9204e87facf",
   "metadata": {},
   "source": [
    "> **REV A0** - HOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1474b40-7ff0-473a-802c-fe63131cefac",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f567de13-74d4-4db1-8e60-103763cd4afe",
   "metadata": {},
   "source": [
    "Diamonds are a highly valued gemstone. They are a complex commodity with a well-defined grading system called the 4C's of Diamonds. These 4C's are: \n",
    "\n",
    "* Cut\n",
    "* Color\n",
    "* Clarity\n",
    "* Carat\n",
    "\n",
    "The purpose of this project is to model diamond prices by analyzing the relationship between the 4C's and the price of a diamond."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ee673b-db1a-4d49-a56b-457b00ddd350",
   "metadata": {},
   "source": [
    "# OBJECTIVES "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0babcaf2-742a-4708-8861-b60a9bcab70f",
   "metadata": {},
   "source": [
    "The objectives of this project are as follows:\n",
    "\n",
    "1. **Identify Key Factors:** Determine which diamond characteristics have the most significant impact on pricing.\n",
    "2. **Model Development:** Develop predictive models that estimate diamond prices based on their characteristics.\n",
    "3. **Insight Generation:** Gain insights into diamond pricing that allows consumers to see their options based on price.\n",
    "4. **Recommendations:** Provide recommendations that can be used by the consumer, according to the analysis findings and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c6dfb-1241-4800-acdf-d85bc3f3bcad",
   "metadata": {},
   "source": [
    "# DATA SOURCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed128566-42dc-44b9-a720-1d49471a3d0b",
   "metadata": {},
   "source": [
    "A data source is the primary location where data is collected and stored. Data can be stored in either unstructured, semi-structured, and structured formats. Sources of data can include:\n",
    "\n",
    "* Databases\n",
    "* Files\n",
    "* APIs\n",
    "* Web Scraping\n",
    "* Sensors and IoT Devices\n",
    "* Cloud Services\n",
    "* External Partners\n",
    "\n",
    "Each data source has its own characteristics, including data format, structure, accessibility, and frequency of updates. Understanding these differences is crucial for selecting the appropriate tools and techniques for data extraction. \n",
    "\n",
    "There is only 1 data source for this project, described below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c71102c-3e45-406d-8548-ea6b62632c47",
   "metadata": {},
   "source": [
    "## KAGGLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3aebd-c4ce-4d53-93c7-8fe1241b0082",
   "metadata": {},
   "source": [
    "The dataset used in this project can be found on [the kaggle website](https://www.kaggle.com/). Kaggle is a popular platform for data science and machine learning competitions, datasets, and learning resources. It was founded in 2010 and acquired by Google in 2017.\n",
    "\n",
    "The kaggle website where the dataset can be downloaded is: [Diamonds - Analyze diamonds by their cut, color, clarity, prices and other attributes](https://www.kaggle.com/datasets/shivam2503/diamonds). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f3e8e-a3e3-4e0f-9dff-865a5d577cf8",
   "metadata": {},
   "source": [
    "### ATTRIBUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553b512-0094-4b30-9631-1c404fdae18a",
   "metadata": {},
   "source": [
    "The person credited with creating this dataset is: `Shivam Agrawal`. See [Diamonds - Analyze diamonds by their cut, color, clarity, prices and other attributes](https://www.kaggle.com/datasets/shivam2503/diamonds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e860a0-8d6f-428c-a1ac-197c8e97d97c",
   "metadata": {},
   "source": [
    "### DESCRIPTION OF DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f9f63-5bf5-470f-8b38-25a3defe47ae",
   "metadata": {},
   "source": [
    "The dataset is a csv file containing information on various diamond characteristics, and their corresponding prices. The features found in this dataset are:\n",
    "\n",
    "| Feature | Description      |\n",
    "|---------|------------------|\n",
    "| carat   | The weight of the diamond, measured in carats |\n",
    "| cut     | The quality of the diamond's cut, ranging from 'Fair' to 'Ideal' |\n",
    "| clarity | The level of imperfections or blemishes within the diamond, categorized from 'I1' (worst) to the best: 'IF' (internally flawless) |\n",
    "| color   | The color grade of the diamond, ranging from 'J' (worst) to 'D' (best) |\n",
    "| x       | Diamond length in mm |\n",
    "| y       | Diamond width in mm |\n",
    "| z       | Diamond depth in mm |\n",
    "| depth   | Total depth percentage = z / mean(x, y) = 2 * z / (x + y) |\n",
    "| table   | Width of top of diamond relative to widest point |\n",
    "| price   | The price of the diamond, in USD. This is the target feature |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fbd4ca-801c-44a2-bf45-c24a88b9a0c2",
   "metadata": {},
   "source": [
    "# METHODOLOGY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9464339-874f-4887-88a8-4e761b062e3a",
   "metadata": {},
   "source": [
    "The most effective methodology for extracting actionable insights from data is to use a 3 step analytical process. The steps in this process are as follows: \n",
    "\n",
    "1. **Descriptive Analytics:** involves the exploration and summarization of historical data to understand past trends and patterns. It provides a foundational understanding of what happened, offering valuable context for further analysis. \n",
    "2. **Predictive Analytics:** utilizes statistical algorithms and machine learning techniques to forecast future outcomes, based on historical data patterns. By identifying potential future trends and behaviors, predictive analytics empowers organizations to anticipate opportunities and mitigate risks.\n",
    "3. **Prescriptive Analytics:** takes the analysis a step further by recommending actions or strategies to optimize outcomes. It leverages advanced modeling techniques to simulate various scenarios and determine the most effective course of action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee08896-dcb6-49f8-a3db-5d6757a675af",
   "metadata": {},
   "source": [
    "## SCOPE OF DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf9428-b784-43f0-b1e7-566c09327413",
   "metadata": {},
   "source": [
    "This notebook describes the **Descriptive Analytics** step. The Predictive and Prescriptive Analytics steps will be described in other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5905b2f-487e-4e0c-8f4a-1986fed8ec40",
   "metadata": {},
   "source": [
    "# DESCRIPTIVE ANALYTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fe5d8-81ff-446f-916f-9dd97c66c804",
   "metadata": {},
   "source": [
    "Descriptive analytics lays the foundation for data-driven decision-making. It provides a comprehensive understanding of historical data patterns and trends. The workflow that will be followed in performing descriptive analytics is shown below:\n",
    "\n",
    "<img \n",
    "     src=\"../../00_Data/01_Assets/DescriptiveAnalytics.png\" \n",
    "     alt=\"Descriptive Analytics Workflow\"\n",
    "     style=\"width:1000x;height:450px;\"\n",
    "     >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56635b1-5517-4c25-9bf5-437ac5f547c9",
   "metadata": {},
   "source": [
    "## ETL (EXTRACT, TRANSFORM, LOAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5341ca56-9aa4-49ba-be62-544aaaa46b31",
   "metadata": {},
   "source": [
    "ETL stands for Extract, Transform, Load. It refers to the process of extracting raw data from a data source, transforming data into a tabular dataset, and loading data to a target destination such as a folder or database. The process of creating a tabular dataset plays a critical role in ensuring data quality, consistency, and usability for analysis. \n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "  <h3 class=\"alert-heading\">What is a tabular dataset?</h3>\n",
    "  <p>A tabular dataset is a structured form of data, commonly used in analytics and machine learning. It organizes data into rows and columns, where each row represents an individual observation or record, and every column represents a specific attribute or feature of the data.</p>\n",
    "  <hr>\n",
    "  <p class=\"mb-0\">Tabular datasets are typically stored in formats such as CSV (Comma-separated values), spreadsheets, or relational databases, and they are widely used in various domains for storing, analyzing, and visualizing data.</p>\n",
    "</div>\n",
    "\n",
    "Below is an explanation of the ETL process:\n",
    "\n",
    "1. **Extract:**\n",
    "\n",
    "    * **Data Source Connectivity:** ETL tools or scripts are used to connect to the data sources and retrieve the necessary data. This may involve querying databases, reading files, or pulling data from APIs.\n",
    "\n",
    "    * **Data Extraction:** The extraction phase involves retrieving raw data from a data source. Some examples of common data sources include:\n",
    "      \n",
    "        *  Files (music, images, spreadsheets, or other digital files)\n",
    "        *  Databases\n",
    "        *  APIs,\n",
    "        *  Web services\n",
    "        *  Web scraping\n",
    "        *  Streaming data sources\n",
    "        \n",
    "        Data can be extracted in its raw form, or from a structured / semi-structured format such as: CSV, JSON, XML, or relational databases.\n",
    "\n",
    "3. **Transform:**\n",
    "\n",
    "    * **Cleaning and Standardization:** Creating a [tidy compliant](https://about.dataclassroom.com/blog/keep-your-data-tidy) dataset by cleaning, handling missing values, removing duplicates, correcting errors, and standardizing data and data type formats.\n",
    "\n",
    "5. **Load:**\n",
    "\n",
    "   * **Data Loading Strategies:** Describe how often is the data updated, and what kind of data pipeline is required in order to use in a continuous analytics or machine learning project.\n",
    "   * **Destination Schema:** Define the format that will be used. CSV is the most common, but data if stored in a data warehouse, lake or databases typically load data into a predefined schema or data model in the target destination. This ensures consistency and compatibility with downstream analytics and reporting tools.\n",
    "    * **Data Loading:** The load phase involves loading the transformed data into a target destination, such as a folder, data warehouse, data lake, or database. This can be a one-time load or a continuous process, depending on the frequency of data updates and the requirements of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac52836-7d0f-401a-b091-c9226122f667",
   "metadata": {},
   "source": [
    "### SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20140189-8277-4a89-875c-4918b8305edf",
   "metadata": {},
   "source": [
    "* ETL is the process of creating a tabular dataset from a data source.\n",
    "* The ETL process must be documented for every data source used on a project.\n",
    "* A dataset is fit-for-purpose if it is [tidy compliant](https://vita.had.co.nz/papers/tidy-data.pdf).\n",
    "\n",
    "A tidy compliant dataset allows for efficient data analysis that reduces errors, improves data processing, and better data visualization. It is a critical step to set the foundations for analytics and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff6f844-fa0f-4fcd-ae8b-0a3e6607db27",
   "metadata": {},
   "source": [
    "## DATA MINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c02b47-4893-4c5a-abc6-0a8de2288c63",
   "metadata": {},
   "source": [
    "The goal of data mining is to combine all the datasets created during ETL, into one **main** dataset, and verify the data meets [the tidy specification](https://vita.had.co.nz/papers/tidy-data.pdf), and any other quality requirements, before the data is used in analytics and machine learning. \n",
    "\n",
    "The steps used to create this dataset are as follows:\n",
    "\n",
    "1. **Data Collection:** Gather the relevant datasets, and store them together.\n",
    "2. **Data Selection:** Identify relevant data, in each dataset, that contain information pertinent to the analysis objectives.\n",
    "3. **Data Integration:** Combine the selected data together into 1 dataset, creating a unified dataset for analysis.\n",
    "4. **Data Cleaning:** Perform data cleaning processes to handle missing values, duplicates, and inconsistencies. Clean data is data that meets [the tidy specification](https://vita.had.co.nz/papers/tidy-data.pdf). \n",
    "5. **Data Transformation:** Transform the data where required, making the dataset suitable for analysis and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8f3296-b774-420c-afba-499ba8331fa8",
   "metadata": {},
   "source": [
    "### SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ed4d4-dfda-46cc-8b8c-22b797406d43",
   "metadata": {},
   "source": [
    "* Data Mining is the process of combining multiple datasets into 1 main dataset.\n",
    "* It allows for the dataset to be explainable, repeatable, and reproducible.\n",
    "* This process also validates that the dataset complies with the [tidy specification](https://vita.had.co.nz/papers/tidy-data.pdf).\n",
    "\n",
    "This process ensures that high quality data is used in analytics and machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f6964-101d-4e90-842f-308cdf1b1bd3",
   "metadata": {},
   "source": [
    "## DESCRIPTIVE STATISTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d33d5-10b0-464a-be81-096b03c5c261",
   "metadata": {},
   "source": [
    "Descriptive statistics is the analytics starting point. It is essential for understanding the basic properties of a dataset, and identifying patterns & trends. This information serves as a foundation for further analysis, hypothesis testing, and model building. Descriptive statistics provides methods for organizing, visualizing, and analyzing data to gain insights into its characteristics and distributions. Descriptive statistics helps to understand the central tendency, variability, and distribution of data without making inferences or generalizations to a larger population.\n",
    "\n",
    "The dataset will be described as follows: \n",
    "\n",
    "* **Measures of Central Tendency:** Calculate descriptive statistics such as mean, median, and mode to understand the central tendency of the data.\n",
    "* **Measures of Dispersion:** Compute measures like standard deviation, variance, and range to assess the spread or variability of the data.\n",
    "* **Frequency Distributions:** Create frequency tables or histograms to visualize the distribution of categorical and numerical variables.\n",
    "* **Percentiles:** Calculate percentiles to identify specific data points' position within the dataset.\n",
    "* **Skewness and Kurtosis:** Skewness measures the asymmetry of the distribution, indicating whether the data is skewed to the left or right. Kurtosis measures the peakedness or flatness of the distribution.\n",
    "* **Correlation Analysis:** Compute correlation coefficients to understand the relationships between pairs of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1338f986-0d26-4d7f-8b43-457f3267e46a",
   "metadata": {},
   "source": [
    "### SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a61440-2136-4894-b242-55ae482f1cef",
   "metadata": {},
   "source": [
    "* Descriptive statistics offers a high-level overview of the dataset.\n",
    "* Enables a deep understanding of the data, helping identify potential issues. or setting the expectations of how the data can be used in analytics and machine learning.\n",
    "* Provides a concise summary of the data, helping understand the underlying characteristics, patterns, and trends.\n",
    "\n",
    "Descriptive statistics validates that the dataset is fit-for-purpose, explainable, repeatable, and reproducible. It provides valuable context for more advanced analytical techniques, such as predictive and prescriptive analytics, enabling organizations to build upon this foundational knowledge to make more accurate forecasts and informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c0d932-ffc1-42fd-bebf-0f1d76cef81f",
   "metadata": {},
   "source": [
    "## EDA (EXPLORATORY DATA ANALYTICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656cb2f0-6fb2-4d15-a5c7-f504eeb850ee",
   "metadata": {},
   "source": [
    "The primary goal of EDA is to understand the data and uncover patterns, trends, relationships, and anomalies that may be present in the data. It involves exploring and visualizing the data to gain an understanding of its characteristics, distributions, and relationships. EDA helps identify potential patterns and insights that can guide further analysis. \n",
    "\n",
    "The Key components of EDA include:\n",
    "\n",
    "* **Univariate Analysis:** Explore individual variables to understand their distributions, outliers, and potential patterns.\n",
    "* **Bivariate Analysis:** Investigate relationships between pairs of variables through scatter plots, correlation matrices, or box plots.\n",
    "* **Multivariate Analysis:** Examine interactions between multiple variables using techniques like heatmaps, pair plots, or dimensionality reduction methods.\n",
    "* **Visualization:** Create visualizations such as histograms, bar charts, line plots, and heatmaps to represent data distributions and relationships effectively.\n",
    "* **Pattern Identification:** Identify trends, anomalies, clusters, or patterns within the data using statistical methods or visualization tools.\n",
    "* **Hypothesis Generation:** The process of formulating potential explanations or theories about relationships, patterns, or phenomena observed in the data. Hypothesis generation is a critical step in the data analysis process as it guides further investigation and hypothesis testing to validate or refute the proposed hypotheses.\n",
    "* **ANOVA (Analysis of Variance):** A statistical technique used to analyze differences among means of three or more groups. It determines whether there are statistically significant differences between the means of two or more independent groups. ANOVA is only performed where required, and is subject to a project change order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e3945-0778-452c-b7e4-608f72609155",
   "metadata": {},
   "source": [
    "### SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288072df-fbcf-4bd4-8568-c717fd31b8be",
   "metadata": {},
   "source": [
    "* EDA is a conversation with the data.\n",
    "* The specific techniques and tools used will vary depending on the dataset.\n",
    "* You gain a deeper understanding of your dataset, setting the stage for informed modeling, analysis, and insights!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d4a2c-23a0-42fd-9cc0-4d6b2ebcc440",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254403c7-4add-4b08-b02f-ef1188857db5",
   "metadata": {},
   "source": [
    "This notebook describes the project objectives, and the methodology that will be followed in executing and analytical project that is explainable, repeatable, and reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1d71f-438d-4874-81df-82ae5467cc72",
   "metadata": {},
   "source": [
    "## NEXT STEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0f359-2c27-4c5a-8574-2e8d8d71fdcd",
   "metadata": {},
   "source": [
    "NOTEBOOK 00_02 describes the business rules related to diamond pricing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
