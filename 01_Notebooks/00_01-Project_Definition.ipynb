{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2493340-0992-4dbc-b00d-0894395111d3",
   "metadata": {},
   "source": [
    "<h1 style='color:rgb(52, 152, 219)'; align=center><font size = 8> DIAMOND PRICES - ANALYSIS AND MODELING </font></h1>\n",
    "\n",
    "<h2 style='color:rgb(52, 152, 219)'; align=left><font size = 6> NOTEBOOK 1 - OBJECTIVES & METHODOLOGY </font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f681aaf-4992-4617-8cfe-a1c0f601b17f",
   "metadata": {},
   "source": [
    "# REVISION HISTORY\n",
    "\n",
    "| REV | DESCRIPTION             | DATE         |  BY   | CHECK | APPROVE  |\n",
    "|:---:|:-----------------------:|:------------:|:-----:|:-----:|:--------:|\n",
    "| A0  | ISSUED FOR REVIEW (IFR) | 2024-APR-XX  |  IAC  |       |          |\n",
    "|     |                         |              |       |       |          |\n",
    "\n",
    "## DETAILED DESCRIPTION OF REVISIONS\n",
    "\n",
    "> **REV A0** - HOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1474b40-7ff0-473a-802c-fe63131cefac",
   "metadata": {},
   "source": [
    "# INTRODUCTION\n",
    "\n",
    "The purpose of this project is analyze and model the price of diamonds, based on a dataset obtained from [kaggle](https://www.kaggle.com/). The analysis of a dataset containing features related to diamond characteristics, and their corresponding prices, presents an intriguing opportunity to develop the critical thinking skills needed when analyzing and modeling data. Diamonds are a highly valued gemstone. Understanding the factors that influence their pricing is of great interest to various stakeholders, including: jewelers, consumers, and investors. In this project, we aim to explore the following:\n",
    "\n",
    "* How diamond characteristics such as carat weight, cut, clarity, and color relate to diamond prices\n",
    "* Are there any other features that can be considered when modeling diamond prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ee673b-db1a-4d49-a56b-457b00ddd350",
   "metadata": {},
   "source": [
    "# OBJECTIVES\n",
    "\n",
    "The objectives of this project are as follows:\n",
    "\n",
    "1. **Identify Key Factors:** Determine which diamond characteristics have the most significant impact on pricing.\n",
    "2. **Model Development:** Develop predictive models that estimate diamond prices based on their characteristics.\n",
    "3. **Insight Generation:** Gain insights into diamond pricing that allows consumers to see their options based on price.\n",
    "4. **Recommendations:** Provide recommendations that can be used by the consumer, according to the analysis findings and modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8a8f24-d4fc-436c-8859-93e8bb4c2856",
   "metadata": {},
   "source": [
    "# DATA DESCRIPTION\n",
    "\n",
    "## DATA SOURCE\n",
    "\n",
    "The dataset used in this project can be found on [kaggle](https://www.kaggle.com/). The following link will take you to the place where the dataset is stored: [Diamonds - Analyze diamonds by their cut, color, clarity, prices and other attributes](https://www.kaggle.com/datasets/shivam2503/diamonds). \n",
    "\n",
    "### ATTRIBUTION\n",
    "\n",
    "The person credited with creating the dataset is: Shivam Agrawal.\n",
    "\n",
    "## DATASET\n",
    "\n",
    "The dataset contains information on various diamond characteristics and their corresponding prices. Key features include:\n",
    "\n",
    "> **Carat:** The weight of the diamond, measured in carats.\n",
    "\n",
    "> **Cut:** The quality of the diamond's cut, ranging from 'Fair' to 'Ideal'.\n",
    "\n",
    "> **Clarity:** The level of imperfections or blemishes within the diamond, categorized from 'I1' (worst) to the best: 'IF' (internally flawless).\n",
    "\n",
    "> **Color:** The color grade of the diamond, ranging from 'J' (worst) to 'D' (best).\n",
    "\n",
    "> **x:** Diamond length in mm\n",
    "\n",
    "> **y:** Diamond width in mm\n",
    "\n",
    "> **z:** Diamond depth in mm\n",
    "\n",
    "> **Depth:** Total depth percentage = z / mean(x, y) = 2 * z / (x + y)\n",
    "\n",
    "> **Table:** Width of top of diamond relative to widest point\n",
    "\n",
    "> **Price:** The price of the diamond, in USD. This is the target feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fbd4ca-801c-44a2-bf45-c24a88b9a0c2",
   "metadata": {},
   "source": [
    "# METHODOLOGY\n",
    "\n",
    "A comprehensive methodology for extracting insights and making informed decisions consists in performing analytics in a 3 step process:\n",
    "\n",
    "1. **Descriptive Analytics:** involves the exploration and summarization of historical data to understand past trends and patterns. It provides a foundational understanding of what has happened, offering valuable context for further analysis. \n",
    "2. **Predictive Analytics:** utilizes statistical algorithms and machine learning techniques to forecast future outcomes based on historical data patterns. By identifying potential future trends and behaviors, predictive analytics empowers organizations to anticipate opportunities and mitigate risks.\n",
    "3. **Prescriptive Analytics:** takes the analysis a step further by recommending actions or strategies to optimize outcomes. It leverages advanced modeling techniques to simulate various scenarios and determine the most effective course of action.\n",
    "\n",
    "By integrating all three approaches, valuable insights can be gained. Insights that drive strategic decision-making and enhance business performance.\n",
    "\n",
    "This notebook will describe the methodology for the Descriptive Analytics phase. Predictive and Prescriptive Analytics methodologies will be explored in other notebooks.\n",
    "\n",
    "## DESCRIPTIVE ANALYTICS\n",
    "\n",
    "Descriptive analytics plays a crucial role in understanding and summarizing datasets to derive meaningful insights. Descriptive Analytics is a structured methodology encompassing:\n",
    "\n",
    "* Data Mining\n",
    "* ETL (Extract, Transform, Load)\n",
    "* Descriptive Statistic\n",
    "* EDA (Exploratory Data Analysis)\n",
    "\n",
    "That can effectively uncover patterns, trends, and relationships within the data; facilitating informed decision-making and driving business value.\n",
    "\n",
    "### DATA MINING\n",
    "\n",
    "The goal of data mining is to create a tabular dataset. A tabular dataset is a structured form of data representation commonly used in analytics and machine learning. It organizes data into rows and columns, where each row represents an individual observation or record, and each column represents a specific attribute or feature of the data. Tabular datasets are typically stored in formats such as CSV (Comma-separated values), Excel spreadsheets, or relational databases, and they are widely used in various domains for storing, analyzing, and visualizing data.\n",
    "\n",
    "The following tasks are the steps that will be utilized in creating a tabular dataset :\n",
    "\n",
    "* **Data Collection:** Gather raw data from various sources such as databases, APIs, files, or web scraping.\n",
    "* **Data Selection:** Identify relevant datasets that contain information pertinent to the analysis objectives.\n",
    "* **Data Integration:** Combine multiple datasets if necessary to create a unified dataset for analysis.\n",
    "* **Data Cleaning:** Perform data cleaning processes to handle missing values, outliers, duplicates, and inconsistencies.\n",
    "* **Data Transformation:** Transform the data into a tabular dataset suitable for analysis, including converting data types and scaling numeric variables.\n",
    "\n",
    "#### QUALITY REVIEW\n",
    "\n",
    "Data sets must be quality reviewed, and approved by all project stakeholders before proceeding to the next step. A quality review is essential for ensuring data quality, and keeping stakeholders engaged on progress. If the dataset fails the quality review, the project will need to decide on the following:\n",
    "\n",
    "1. If any changes are required, thus implementing change management plans\n",
    "2. The feasibility, and risks to the project because of data mining rework\n",
    "\n",
    "### ETL (EXTRACT, TRANSFORM, LOAD)\n",
    "\n",
    "The purpose of ETL is to create a data set that complies with the [Tidy Specification](https://about.dataclassroom.com/blog/keep-your-data-tidy). \n",
    "ETL stands for Extract, Transform, Load, and it refers to the process of extracting data from various sources, transforming it into a [Tidy Compliant](https://about.dataclassroom.com/blog/keep-your-data-tidy) format, and loading it into a target destination, typically a data warehouse or a database. ETL is a fundamental step in data integration and plays a crucial role in ensuring data quality, consistency, and usability for analysis. Here's a detailed explanation of each component of ETL:\n",
    "\n",
    "1. **Extract:**\n",
    "\n",
    "* **Data Extraction:** The extraction phase involves retrieving data from multiple sources, which can include databases, files, APIs, web services, or streaming data sources. Data can be extracted in its raw form or in structured formats such as CSV, JSON, XML, or relational databases.\n",
    "* **Data Source Connectivity:** ETL tools or scripts are used to connect to the data sources and retrieve the necessary data. This may involve querying databases, reading files, or pulling data from APIs.\n",
    "\n",
    "2. **Transform:**\n",
    "\n",
    "* **Data Transformation:** The transformation phase involves cleaning, enriching, and restructuring the extracted data to make it suitable for analysis. This includes tasks such as:\n",
    "Cleaning and Standardization: Handling missing values, removing duplicates, correcting errors, and standardizing data formats.\n",
    "* **Data Enrichment:** Combining data from multiple sources, deriving new variables or features, and performing calculations or aggregations.\n",
    "* **Data Quality Assurance:** Validating data against predefined rules, ensuring consistency, accuracy, and integrity.\n",
    "* **Data Formatting:** Converting data types, units, or formats to ensure compatibility with the target destination.\n",
    "\n",
    "3 **Load:**\n",
    "\n",
    "* **Data Loading:** The load phase involves loading the transformed data into a target destination, such as a data warehouse, data lake, or database. This can be a one-time load or a continuous process, depending on the frequency of data updates and the requirements of the analysis.\n",
    "* **Destination Schema:** ETL processes typically load data into a predefined schema or data model in the target destination. This ensures consistency and compatibility with downstream analytics and reporting tools.\n",
    "* **Data Loading Strategies:** ETL processes may use various loading strategies, such as full loading, incremental loading, or delta loading, depending on the volume of data and the requirements of the analysis.\n",
    "\n",
    "#### QUALITY REVIEW\n",
    "\n",
    "Data sets must be quality reviewed, and approved by all project stakeholders before proceeding to the next step. A quality review is essential for ensuring data quality, and keeping stakeholders engaged on progress. If the dataset fails the quality review, the project will need to decide on the following:\n",
    "\n",
    "1. If any changes are required, thus implementing change management plans\n",
    "2. The feasibility, and risks to the project because of data mining rework\n",
    "\n",
    "### DESCRIPTIVE STATISTICS\n",
    "\n",
    "Descriptive statistics provide valuable insights into the characteristics and distribution of data, helping to summarize and interpret datasets effectively. This information serves as a foundation for further analysis, hypothesis testing, and model building.  It provides methods for organizing, visualizing, and analyzing data to gain insights into its characteristics, distributions, and patterns. Descriptive statistics helps in understanding the central tendency, variability, and distribution of data without making inferences or generalizations to a larger population.\n",
    "\n",
    "The tasks that are performed to complete this task are:\n",
    "\n",
    "* **Measures of Central Tendency:** Calculate descriptive statistics such as mean, median, and mode to understand the central tendency of the data.\n",
    "* **Measures of Dispersion:** Compute measures like standard deviation, variance, and range to assess the spread or variability of the data.\n",
    "* **Frequency Distributions:** Create frequency tables or histograms to visualize the distribution of categorical and numerical variables.\n",
    "* **Percentiles:** Calculate percentiles to identify specific data points' position within the dataset.\n",
    "* **Skewness and Kurtosis:** Skewness measures the asymmetry of the distribution, indicating whether the data is skewed to the left or right. Kurtosis measures the peakedness or flatness of the distribution.\n",
    "* **Correlation Analysis:** Compute correlation coefficients to understand the relationships between pairs of variables.\n",
    "\n",
    "#### QUALITY REVIEW\n",
    "\n",
    "The quality review for this step in the process ensures the fit-for-purpose state of the data, before proceeding to EDA.\n",
    "\n",
    "### EDA (EXPLORATORY DATA ANALYTICS)\n",
    "\n",
    "The primary goal of EDA is to understand the data and uncover patterns, trends, relationships, and anomalies that may be present in the data. EDA involves exploring and visualizing the data to gain an understanding of its characteristics, distributions, and relationships. EDA helps identify potential patterns and insights that can guide further analysis. \n",
    "\n",
    "The Key components of EDA include:\n",
    "\n",
    "* **Univariate Analysis:** Explore individual variables to understand their distributions, outliers, and potential patterns.\n",
    "* **Bivariate Analysis:** Investigate relationships between pairs of variables through scatter plots, correlation matrices, or box plots.\n",
    "* **Multivariate Analysis:** Examine interactions between multiple variables using techniques like heatmaps, pair plots, or dimensionality reduction methods.\n",
    "* **Visualization:** Create visualizations such as histograms, bar charts, line plots, and heatmaps to represent data distributions and relationships effectively.\n",
    "* **Pattern Identification:** Identify trends, anomalies, clusters, or patterns within the data using statistical methods or visualization tools.\n",
    "* **Hypothesis Generation:** The process of formulating potential explanations or theories about relationships, patterns, or phenomena observed in the data. Hypothesis generation is a critical step in the data analysis process as it guides further investigation and hypothesis testing to validate or refute the proposed hypotheses.\n",
    "* **ANOVA (Analysis of Variance):** A statistical technique used to analyze differences among means of three or more groups. It determines whether there are statistically significant differences between the means of two or more independent groups. ANOVA is only performed where required, and is subject to a project change order.\n",
    "\n",
    "#### QUALITY REVIEW\n",
    "\n",
    "The quality review for EDA consists of doing the following:\n",
    "\n",
    "1. **Testability and Falsifiability:** To test the hypothesis. A good hypothesis is testable and falsifiable, meaning that it can be empirically tested using data and potentially proven wrong. Hypotheses should be formulated in a way that allows for hypothesis testing through statistical analysis or experimentation.\n",
    "2. **Validating ANOVA:** Confirm that all stakeholders approve the results of the ANOVA test.\n",
    "  \n",
    "### CONCLUSION\n",
    "\n",
    "Descriptive analytics serves as a vital cornerstone in the analytics toolkit, offering essential insights into past trends and patterns. By delving into historical data, organizations can gain a solid understanding of their current state, identify areas of strength and weakness, and uncover potential opportunities for improvement. Moreover, descriptive analytics provides valuable context for more advanced analytical techniques, such as predictive and prescriptive analytics, enabling organizations to build upon this foundational knowledge to make more accurate forecasts and informed decisions. Ultimately, by harnessing the power of descriptive analytics, businesses can enhance their understanding of the past and present, paving the way for smarter strategies and better outcomes in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d4a2c-23a0-42fd-9cc0-4d6b2ebcc440",
   "metadata": {},
   "source": [
    "# SUMMARY\n",
    "\n",
    "This notebook describes the project objectives, and the methodology that will be followed in executing work in an explainable, repeatable, and reproducible fashion. \n",
    "\n",
    "## NEXT STEPS\n",
    "\n",
    "NOTEBOOK 2 describes the business rules related to diamond pricing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
